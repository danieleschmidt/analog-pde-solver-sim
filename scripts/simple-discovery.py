#!/usr/bin/env python3
"""
Simplified Autonomous Value Discovery for demonstration.
"""

import json
import os
import subprocess
from datetime import datetime, timezone
from pathlib import Path


def discover_todo_fixme_patterns():
    """Find TODO, FIXME, HACK patterns in code."""
    items = []
    patterns = ["TODO", "FIXME", "HACK", "XXX"]
    
    for pattern in patterns:
        try:
            result = subprocess.run([
                "rg", "--no-heading", "--line-number", pattern, ".", 
                "--type", "py", "--type", "md", "--type", "yaml"
            ], capture_output=True, text=True, cwd="/root/repo")
            
            if result.returncode == 0:
                for line in result.stdout.strip().split('\n'):
                    if line.strip():
                        parts = line.split(':', 2)
                        if len(parts) >= 3:
                            file_path, line_num, content = parts
                            items.append({
                                "id": f"td-{len(items)+1:03d}",
                                "title": f"Address {pattern} in {file_path}",
                                "category": "technical_debt", 
                                "file": file_path,
                                "line": int(line_num),
                                "content": content.strip(),
                                "estimated_effort": 2.0 if pattern == "FIXME" else 1.0,
                                "business_value": 40,
                                "composite_score": 65.0,
                                "discovered_date": datetime.now(timezone.utc).isoformat()
                            })
        except subprocess.SubprocessError:
            continue
    
    return items


def discover_missing_tests():
    """Find Python functions that might need tests."""
    items = []
    
    try:
        # Find Python functions
        result = subprocess.run([
            "rg", "--no-heading", "--line-number", r"def \w+\(", "analog_pde_solver/", "--type", "py"
        ], capture_output=True, text=True, cwd="/root/repo")
        
        if result.returncode == 0:
            for i, line in enumerate(result.stdout.strip().split('\n')[:5]):  # Limit to 5
                if line.strip():
                    parts = line.split(':', 2)
                    if len(parts) >= 3:
                        file_path, line_num, content = parts
                        func_name = content.strip().split('(')[0].replace('def ', '')
                        items.append({
                            "id": f"test-{i+1:03d}",
                            "title": f"Add tests for {func_name} in {file_path}",
                            "category": "testing",
                            "file": file_path,
                            "line": int(line_num),
                            "estimated_effort": 3.0,
                            "business_value": 60,
                            "composite_score": 72.0,
                            "discovered_date": datetime.now(timezone.utc).isoformat()
                        })
    except subprocess.SubprocessError:
        pass
    
    return items


def discover_documentation_gaps():
    """Find missing docstrings."""
    items = []
    
    try:
        # Find functions without docstrings (simplified)
        result = subprocess.run([
            "rg", "--no-heading", "--line-number", r"def \w+\(.*\):\s*$", "analog_pde_solver/", "--type", "py"
        ], capture_output=True, text=True, cwd="/root/repo")
        
        if result.returncode == 0:
            for i, line in enumerate(result.stdout.strip().split('\n')[:3]):  # Limit to 3
                if line.strip():
                    parts = line.split(':', 2)
                    if len(parts) >= 3:
                        file_path, line_num, content = parts
                        func_name = content.strip().split('(')[0].replace('def ', '')
                        items.append({
                            "id": f"doc-{i+1:03d}",
                            "title": f"Add docstring to {func_name} in {file_path}",
                            "category": "documentation",
                            "file": file_path,
                            "line": int(line_num),
                            "estimated_effort": 0.5,
                            "business_value": 30,
                            "composite_score": 58.0,
                            "discovered_date": datetime.now(timezone.utc).isoformat()
                        })
    except subprocess.SubprocessError:
        pass
    
    return items


def discover_security_opportunities():
    """Find potential security improvements."""
    items = [
        {
            "id": "sec-001",
            "title": "Enable GitHub Advanced Security features",
            "category": "security",
            "estimated_effort": 1.0,
            "business_value": 80,
            "composite_score": 85.0,
            "discovered_date": datetime.now(timezone.utc).isoformat()
        },
        {
            "id": "sec-002", 
            "title": "Add SAST scanning to CI pipeline",
            "category": "security",
            "estimated_effort": 2.0,
            "business_value": 70,
            "composite_score": 78.0,
            "discovered_date": datetime.now(timezone.utc).isoformat()
        }
    ]
    return items


def discover_infrastructure_improvements():
    """Find infrastructure and automation opportunities."""
    items = [
        {
            "id": "infra-001",
            "title": "Set up automated dependency updates",
            "category": "infrastructure",
            "estimated_effort": 3.0,
            "business_value": 65,
            "composite_score": 74.0,
            "discovered_date": datetime.now(timezone.utc).isoformat()
        },
        {
            "id": "perf-001",
            "title": "Add performance benchmarking to CI",
            "category": "performance",
            "estimated_effort": 4.0,
            "business_value": 75,
            "composite_score": 78.9,
            "discovered_date": datetime.now(timezone.utc).isoformat()
        }
    ]
    return items


def main():
    print("ðŸ” Running autonomous value discovery...")
    
    # Discover various types of work items
    all_items = []
    
    debt_items = discover_todo_fixme_patterns()
    test_items = discover_missing_tests()
    doc_items = discover_documentation_gaps()
    security_items = discover_security_opportunities()
    infra_items = discover_infrastructure_improvements()
    
    all_items.extend(debt_items)
    all_items.extend(test_items)
    all_items.extend(doc_items) 
    all_items.extend(security_items)
    all_items.extend(infra_items)
    
    # Sort by composite score
    all_items.sort(key=lambda x: x["composite_score"], reverse=True)
    
    results = {
        "discovered_items": {
            "technical_debt": debt_items,
            "testing": test_items,
            "documentation": doc_items,
            "security": security_items,
            "infrastructure": infra_items
        },
        "prioritized_items": all_items,
        "discovery_timestamp": datetime.now(timezone.utc).isoformat(),
        "total_items": len(all_items),
        "new_items": len(all_items)
    }
    
    # Save results
    os.makedirs("/root/repo/.terragon", exist_ok=True)
    with open("/root/repo/.terragon/discovery-output.json", 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"âœ… Discovery complete: {len(all_items)} items found")
    if all_items:
        print(f"ðŸŽ¯ Top priority: [{all_items[0]['id'].upper()}] {all_items[0]['title']} (Score: {all_items[0]['composite_score']})")
    
    # Update BACKLOG.md
    print("ðŸ“ Updating BACKLOG.md...")
    update_backlog(results)
    
    return results


def update_backlog(results):
    """Update BACKLOG.md with discovered items."""
    now = datetime.now(timezone.utc)
    next_execution = now.replace(hour=now.hour + 1, minute=0, second=0, microsecond=0)
    
    prioritized_items = results.get("prioritized_items", [])
    top_10 = prioritized_items[:10] if len(prioritized_items) >= 10 else prioritized_items
    
    # Get next best value item
    next_item = prioritized_items[0] if prioritized_items else None
    
    content = f"""# ðŸ“Š Autonomous Value Backlog

**Repository**: analog-pde-solver-sim  
**Maturity Level**: MATURING (65/100)  
**Last Updated**: {now.isoformat()}  
**Next Execution**: {next_execution.isoformat()}  

## ðŸŽ¯ Next Best Value Item

"""
    
    if next_item:
        content += f"""**[{next_item['id'].upper()}] {next_item['title']}**
- **Composite Score**: {next_item['composite_score']}
- **Category**: {next_item['category'].title()}
- **Estimated Effort**: {next_item['estimated_effort']}h
- **Business Value**: {next_item.get('business_value', 50)}
- **File**: {next_item.get('file', 'Multiple files')}
- **Status**: Ready for execution

"""
    
    content += """## ðŸ“‹ Priority Backlog (Top 10 Items)

| Rank | ID | Title | Score | Category | Effort | Status |
|------|-----|--------|-------|----------|---------|--------|
"""
    
    for i, item in enumerate(top_10, 1):
        category = item['category'].title()
        effort = f"{item['estimated_effort']}h"
        status = "Ready"
        title = item['title'][:60] + ('...' if len(item['title']) > 60 else '')
        
        content += f"| {i} | {item['id'].upper()} | {title} | {item['composite_score']} | {category} | {effort} | {status} |\n"
        
    content += f"""

## ðŸ“ˆ Autonomous Discovery Results

### Latest Scan Results
- **Items Discovered**: {results.get('total_items', 0)}
- **Discovery Timestamp**: {results.get('discovery_timestamp', 'Unknown')}
- **Scan Status**: âœ… Successful

### Category Breakdown
- **Technical Debt**: {len(results.get('discovered_items', {}).get('technical_debt', []))} items
- **Testing Gaps**: {len(results.get('discovered_items', {}).get('testing', []))} items  
- **Documentation**: {len(results.get('discovered_items', {}).get('documentation', []))} items
- **Security**: {len(results.get('discovered_items', {}).get('security', []))} items
- **Infrastructure**: {len(results.get('discovered_items', {}).get('infrastructure', []))} items

## ðŸ”„ Continuous Execution Status

**Autonomous Mode**: âœ… Active  
**Next Scan**: Hourly (automated via GitHub Actions)  
**Execution Trigger**: Push to main, manual dispatch  
**Value Threshold**: 60+ composite score  

## ðŸš€ Ready for Autonomous Execution

The next highest-value item is ready for autonomous execution:

```bash
npx claude-flow@alpha swarm "Execute the highest priority item from BACKLOG.md in repository analog-pde-solver-sim. Use .terragon/ configuration for scoring and validation." --strategy autonomous --claude
```

## ðŸ“Š Value Scoring Methodology

- **WSJF Weight**: 60% (business value emphasis)
- **ICE Weight**: 10% (impact Ã— confidence Ã— ease)  
- **Technical Debt Weight**: 20% (debt reduction focus)
- **Security Boost**: 2.0Ã— multiplier for security items
- **Maturity Adaptation**: Optimized for MATURING repositories

---

*ðŸ¤– Autonomously maintained by Terragon SDLC â€¢ Last discovery: {now.strftime("%Y-%m-%d %H:%M UTC")} â€¢ Items ready for execution: {len([i for i in top_10 if i.get('composite_score', 0) > 60])}/10*
"""
    
    with open("/root/repo/BACKLOG.md", 'w') as f:
        f.write(content)
    
    print("âœ… BACKLOG.md updated successfully")


if __name__ == "__main__":
    main()